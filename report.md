# Fast Python on CUDA-capable GPUs

## Abstract

Though Python has many advantages such as its flexibility and simple expressive syntax, it is considered as poor performance in terms of massive data processes and computation. To accelarate the computation speed of Python, we came up with the idea of using CUDA-capable GPUs. In our final project, we focused on NumbaPro and tried several ways to improve performance like using 'vectorize', CUDA Host API and writing CUDA directly in Python. Up to 700 times of speedup is achieved in the final tests.



## Introduction to Numba and NumbaPro

Numba is a Numpy-aware optimizing compiler for Python. Numba supports the just-in-time compilation from original Python code to machine code wih the LLVM compiler infrastructure.

			![image](https://github.com/aaron7777/pic/raw/master/1.jpg)


## Sample Test

## Write CUDA in Python

## Future Work

## Conclusion

## Reference